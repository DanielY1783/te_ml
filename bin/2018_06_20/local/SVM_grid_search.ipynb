{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes in data from /dors/capra_lab/users/yand1/te_ml/data/2018_06_12_te_enhancers_ml\n",
    "to predict if transposable elements overlap with enhancers given a set of transcription\n",
    "factors. This version uses a grid search to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd # For getting data\n",
    "from sklearn import metrics # Get model metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class constants\n",
    "DATE = \"2018_06_20/\" \n",
    "DIRECTORY = \"../../../\" # Root directory\n",
    "LOC = \"local/\" # local or accre cluster\n",
    "TYPE = \"svc_grid_search/\" # Type of model\n",
    "DATA_FILE = \"test.tsv\" # Name of data file to process\n",
    "CHROMOSOME = 0 # Column for the chromosome number of transposable element\n",
    "START = 1 # Column for the start location of transposable element\n",
    "END = 2 # Column for the end location of transposable element\n",
    "TF = 8 # Column for the transcription factor intersecting with transposable element\n",
    "ENHANCER = 13 # Column for if enhancer is present. 1 means enhancer is present\n",
    "CROSS_VAL = 5 # Number of subdivisions of data for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df (old_df):\n",
    "    \"\"\"transform_tf updates the columns of transcription factors in new_df by cross referencing old_df\n",
    "    \n",
    "    Each row in the old data frame is matched to the corresponding location in the new\n",
    "    data frame.The column of the the transcription factor in the new data frame that corresponds\n",
    "    to the old data frame is incremented by 1. The enhancer column in the new data frame is\n",
    "    set to 1 if that column in the old data frame is 1.\n",
    "    \n",
    "    Args:\n",
    "        old_df(pd.DataFrame): Data frame that contains the information about transcription factors.\n",
    "        \n",
    "    Return:\n",
    "        new_df(pd.DataFrame): New data frame that has columns with the number of times\n",
    "            each transposable element in different locations intersects with each\n",
    "            transcription factor, as well as if an enhancer site is present.\n",
    "    \"\"\"\n",
    "    # Create groups based on chromosome, start location, end location, transcription factor, and if\n",
    "    # transcription factor is present. Get the size of each of those groups, and use unstack to \n",
    "    # change the transcription factors to column indices to create matrix for machine learning input.\n",
    "    # Use reset_index to bring all other labels to top level.\n",
    "    new_df = te_df.groupby([CHROMOSOME, START, END, TF, ENHANCER], sort = False).size().unstack(TF, fill_value = 0).reset_index()\n",
    "\n",
    "    # Reformat enhancer column to have 1 or 0 value.\n",
    "    new_df[ENHANCER] = new_df[ENHANCER].apply(lambda x: 1 if x == \"1\" else 0)\n",
    "\n",
    "    # Rename the columns\n",
    "    new_df.rename(columns = {CHROMOSOME: \"chr\", START: \"start\", END: \"end\", ENHANCER: \"enhancer\"}, inplace = True)\n",
    "\n",
    "    # Sum any repeated rows (in case any rows were identical other than enhancer presence)\n",
    "    new_df.groupby(new_df.index).sum()\n",
    "\n",
    "    # Move row with enhancer to the end.\n",
    "    enhancer_df = new_df.copy()[\"enhancer\"]\n",
    "    new_df.drop(labels = [\"enhancer\"], axis = 1, inplace = True)\n",
    "    new_df.insert(len(new_df.columns), \"enhancer_actual\", enhancer_df)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions(model, x_df, y_df):\n",
    "    \"\"\"create_predictions splits the data into a training and testing set,\n",
    "        oversamples the training set, performs cross validation and predicts the testing set.\n",
    "        \n",
    "    Args:\n",
    "        model(sklearn.ensemble.RandomForestClassifier): The machine learning model to train and predict with\n",
    "        x_df(pd.DataFrame): Input \"x\" vector to test\n",
    "        y_df(pd.DataFrame): Output \"y\" vector with real y values\n",
    "    \"\"\"  \n",
    "    # Use model to predict the testing set\n",
    "    y_pred = model.predict(x_df)\n",
    "    \n",
    "    # Create a confusion matrix and write to file.\n",
    "    cm_df = pd.DataFrame(metrics.confusion_matrix(y_df, y_pred), index = [\"actual_negative\", \"actual_positive\"]\n",
    "                    , columns = [\"predicted_negative\", \"predicted_positive\"])\n",
    "    cm_df.to_csv((DIRECTORY + \"results/\" + DATE + LOC + TYPE + \"confusion_matrix.csv\"), sep = '\\t', mode = \"w+\")\n",
    "    \n",
    "    # Create a file to store metrics.\n",
    "    metrics_file = open((DIRECTORY + \"results/\" + DATE + LOC + TYPE + \"metrics.txt\"), \"w+\")\n",
    "    metrics_file.write(metrics.classification_report(y_df, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Main\n",
    "\n",
    "# Open the transposable elements data as a dataframe.\n",
    "te_df = pd.read_table((DIRECTORY + \"data/2018_06_12_te_enhancers_ml/\" + DATA_FILE), header = None)\n",
    "\n",
    "# Create new data frame for machine learning model by setting columns as the different transcription\n",
    "# factors from the original data frame. Each row will now have the location of the transposable \n",
    "# element, the number of intersections with each transcription factor, and if there is an overlap\n",
    "# with an enhancer.\n",
    "te_new_df = transform_df(te_df)\n",
    "\n",
    "# Get index number for the \"y\" vector for machine learning model.\n",
    "end_index = len(te_new_df.columns) - 1\n",
    "# Set the machine learning input vector as all columns of transcription factors.\n",
    "x_df = te_new_df.iloc[:,3:end_index]\n",
    "# Set the machine learning prediction vector as the last column, which tells if enhancer is present.\n",
    "y_df = te_new_df.iloc[:,end_index]\n",
    "\n",
    "# Split the data into training and testing data.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df)\n",
    "\n",
    "# Perform a grid search to find the best parameters\n",
    "parameters = {\"kernel\": [\"poly\", \"rbf\", \"sigmoid\"], \"C\": [0.01, 0.1, 1, 10, 100, 1000], \"gamma\": [0.000000001, \"auto\", 0.0000001, 0.00001, 0.001, 0.1]}\n",
    "model = GridSearchCV(SVC(cache_size = 10000), param_grid = parameters, n_jobs = -1, scoring = \"f1_macro\", cv = CROSS_VAL)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Print out the best parameters from the grid search.\n",
    "print(\"Best params: \" + str(model.best_params_))\n",
    "print(\"Best score: \" + str(model.best_score_))\n",
    "\n",
    "# Create predictions with SVM model and get metrics.\n",
    "create_predictions(model = model, x_df = x_test, y_df = y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
