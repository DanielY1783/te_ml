{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd # For getting data\n",
    "from sklearn import metrics # Get model metrics\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score # For cross validation\n",
    "from sklearn.model_selection import cross_val_predict \n",
    "from imblearn import over_sampling # Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class constants\n",
    "DATE = \"2018_06_19/\" \n",
    "DIRECTORY = \"../../../\" # Root directory\n",
    "LOC = \"local/\" # local or accre cluster\n",
    "DATA_FILE = \"test.tsv\" # Name of data file to process\n",
    "CHROMOSOME = 0 # Column for the chromosome number of transposable element\n",
    "START = 1 # Column for the start location of transposable element\n",
    "END = 2 # Column for the end location of transposable element\n",
    "TF = 8 # Column for the transcription factor intersecting with transposable element\n",
    "ENHANCER = 13 # Column for if enhancer is present. 1 means enhancer is present\n",
    "CROSS_VAL = 10 # Number of subdivisions of data for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dups (old_df, col_names):\n",
    "    \"\"\"Function that takes in an old dataframe and creates a new dataframe with duplicates removed\n",
    "    \n",
    "    Args:\n",
    "        old_df(pd.DataFrame): Data frame to remove duplicates from\n",
    "        col_names(list): List of column names to in string format\n",
    "    \n",
    "    Returns:\n",
    "        New pd.DataFrame that has duplicates removed with reindexing, and renamed columns.\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(old_df)\n",
    "    new_df = new_df.drop_duplicates()\n",
    "    new_df.index = range(len(new_df.iloc[:,0])) # Reindex\n",
    "    # Rename columns\n",
    "    new_df.columns = [\"chr\", \"start\", \"end\"]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_labels (df, col_list):\n",
    "    \"\"\"col_labels creates new columns corresponding to transcription factors and enhancer presence\n",
    "    \n",
    "    Args:\n",
    "        df(pd.DataFrame): Data frame to add columns to\n",
    "        col_list(list): List of transcription factors\n",
    "    \"\"\"\n",
    "    for tf in col_list:\n",
    "        df[tf] = 0\n",
    "    # Create a column for if enhancer overlaps transposable element\n",
    "    df[\"enhancer_actual\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df (old_df):\n",
    "    \"\"\"transform_tf updates the columns of transcription factors in new_df by cross referencing old_df\n",
    "    \n",
    "    Each row in the old data frame is matched to the corresponding location in the new\n",
    "    data frame.The column of the the transcription factor in the new data frame that corresponds\n",
    "    to the old data frame is incremented by 1. The enhancer column in the new data frame is\n",
    "    set to 1 if that column in the old data frame is 1.\n",
    "    \n",
    "    Args:\n",
    "        old_df(pd.DataFrame): Data frame that contains the information about transcription factors.\n",
    "        \n",
    "    Return:\n",
    "        new_df(pd.DataFrame): New data frame that has columns with the number of times\n",
    "            each transposable element in different locations intersects with each\n",
    "            transcription factor, as well as if an enhancer site is present.\n",
    "    \"\"\"\n",
    "    # Create groups based on chromosome, start location, end location, transcription factor, and if\n",
    "    # transcription factor is present. Get the size of each of those groups, and use unstack to \n",
    "    # change the transcription factors to column indices to create matrix for machine learning input.\n",
    "    # Use reset_index to bring all other labels to top level.\n",
    "    new_df = te_df.groupby([CHROMOSOME, START, END, TF, ENHANCER], sort = False).size().unstack(TF, fill_value = 0).reset_index()\n",
    "\n",
    "    # Reformat enhancer column to have 1 or 0 value.\n",
    "    new_df[ENHANCER] = new_df[ENHANCER].apply(lambda x: 1 if x == \"1\" else 0)\n",
    "\n",
    "    # Rename the columns\n",
    "    new_df.rename(columns = {CHROMOSOME: \"chr\", START: \"start\", END: \"end\", ENHANCER: \"enhancer\"}, inplace = True)\n",
    "\n",
    "    # Sum any repeated rows (in case any rows were identical other than enhancer presence)\n",
    "    new_df.groupby(new_df.index).sum()\n",
    "\n",
    "    # Move row with enhancer to the end.\n",
    "    enhancer_df = new_df.copy()[\"enhancer\"]\n",
    "    new_df.drop(labels = [\"enhancer\"], axis = 1, inplace = True)\n",
    "    new_df.insert(len(new_df.columns), \"enhancer_actual\", enhancer_df)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_df, y_df):\n",
    "    \"\"\"test_model checks how well the model performs and writes output to /results directory\n",
    "    \n",
    "    Args:\n",
    "        model(sklearn.ensemble.RandomForestClassifier): The machine learning model to test\n",
    "        x_df(pd.DataFrame): Input \"x\" vector for machine learning\n",
    "        y_df(pd.DataFrame): Output \"y\" vector for machine learning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Randomly oversample the data, since original data contains few 1's (enhancers overlap)\n",
    "    oversampling = over_sampling.RandomOverSampler()\n",
    "    x_resampled, y_resampled = oversampling.fit_sample(x_df, y_df)\n",
    "    \n",
    "    # Perform k-fold cross validation on the random forest model.\n",
    "    cvs = cross_val_score(model, x_resampled, y_resampled, cv = CROSS_VAL)\n",
    "    # Print the cross validation scores to a file.\n",
    "    cvs_df = pd.DataFrame(data = cvs, index = [\"cvs 1\", \"cvs 2\", \"cvs 3\", \"cvs 4\", \"cvs 5\"], columns = [\"score\"])\n",
    "    cvs_df.to_csv((DIRECTORY + \"results/\" + DATE + LOC + \"cross_val_scores.csv\"), sep = '\\t', index = False)\n",
    "    \n",
    "    # Create predictions.\n",
    "    y_pred = cross_val_predict(model, x_resampled, y_resampled, cv = CROSS_VAL)\n",
    "    # Convert the prediction results to a dataframe.\n",
    "    predictions_df = pd.DataFrame(data = y_pred, columns = [\"enhancer_predicted\"])\n",
    "    # Create a dataframe to combine predictions with actual data.\n",
    "    output_df = pd.DataFrame(df.copy()[[\"chr\", \"start\", \"end\", \"enhancer_actual\"]])\n",
    "    # Copy over predictions and print to csv file.\n",
    "    output_df[\"enhancer_predicted\"] = predictions_df\n",
    "    output_df.to_csv((DIRECTORY + \"results/\" + DATE +  LOC + \"predictions.csv\"))\n",
    "    \n",
    "    # Create a confusion matrix and write to file.\n",
    "    cm_df = pd.DataFrame(metrics.confusion_matrix(y_resampled, y_pred), index = [\"actual_negative\", \"actual_positive\"]\n",
    "                    , columns = [\"predicted_negative\", \"predicted_positive\"])\n",
    "    cm_df.to_csv((DIRECTORY + \"results/\" + DATE + LOC + \"confusion_matrix.csv\"), sep = '\\t')\n",
    "    \n",
    "    # Create a file to store metrics.\n",
    "    metrics_file = open((DIRECTORY + \"results/\" + DATE + LOC + \"metrics.txt\"), \"w+\")\n",
    "    metrics_file.write(metrics.classification_report(y_resampled, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-16a28a3ddb07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Get index number for the \"y\" vector for machine learning model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mend_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# Set the machine learning input vector as all columns of transcription factors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mx_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## Main\n",
    "\n",
    "# Open the transposable elements data as a dataframe.\n",
    "te_df = pd.read_table((DIRECTORY + \"data/2018_06_12_te_enhancers_ml/\" + DATA_FILE), header = None)\n",
    "\n",
    "# Create new data frame for machine learning model by setting columns as the different transcription\n",
    "# factors from the original data frame. Each row will now have the location of the transposable \n",
    "# element, the number of intersections with each transcription factor, and if there is an overlap\n",
    "# with an enhancer.\n",
    "te_new_df = transform_df(te_df)\n",
    "\n",
    "# Get index number for the \"y\" vector for machine learning model.\n",
    "end_index = len(df.columns) - 1\n",
    "# Set the machine learning input vector as all columns of transcription factors.\n",
    "x_df = df.copy().iloc[:,3:end_index]\n",
    "# Set the machine learning prediction vector as the last column, which tells if enhancer is present.\n",
    "y_df = df.copy().iloc[:,end_index]\n",
    "\n",
    "# Create a random forest classifier model\n",
    "rfc = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "\n",
    "# Test the random forest classifer model\n",
    "test_model(model = rfc, x_df = x_df, y_df = y_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
