{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class constants\n",
    "DATE = \"2018_06_15/\" \n",
    "DIRECTORY = \"../../../\" # Root directory\n",
    "LOC = \"local/\" # local or accre cluster\n",
    "DATA_FILE = \"test.tsv\" # Name of data file to process\n",
    "CHROMOSOME = 0 # Column for the chromosome number of transposable element\n",
    "START = 1 # Column for the start location of transposable element\n",
    "END = 2 # Column for the end location of transposable element\n",
    "TF = 8 # Column for the transcription factor intersecting with transposable element\n",
    "ENHANCER = 13 # Column for if enhancer is present. 1 means enhancer is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dups (old_df, col_names):\n",
    "    \"\"\"Function that takes in an old dataframe and creates a new dataframe with duplicates removed\n",
    "    \n",
    "    Args:\n",
    "        old_df(pd.DataFrame): Data frame to remove duplicates from\n",
    "        col_names(list): List of column names to in string format\n",
    "    \n",
    "    Returns:\n",
    "        New pd.DataFrame that has duplicates removed with reindexing, and renamed columns.\n",
    "    \"\"\"\n",
    "    new_df = pd.DataFrame(old_df)\n",
    "    new_df = new_df.drop_duplicates()\n",
    "    new_df.index = range(len(new_df.iloc[:,0])) # Reindex\n",
    "    # Rename columns\n",
    "    new_df.columns = [\"chr\", \"start\", \"end\"]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_labels (df, col_list):\n",
    "    \"\"\"col_labels creates new columns corresponding to transcription factors and enhancer presence\n",
    "    \n",
    "    Args:\n",
    "        df(pd.DataFrame): Data frame to add columns to\n",
    "        col_list(list): List of transcription factors\n",
    "    \"\"\"\n",
    "    for tf in col_list:\n",
    "        df[tf] = 0\n",
    "    # Create a column for if enhancer overlaps transposable element\n",
    "    df[\"enhancer_actual\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tf (new_df, old_df):\n",
    "    \"\"\"update_tf updates the columns of transcription factors in new_df by cross referencing old_df\n",
    "    \n",
    "    Each row in the old data frame is matched to the corresponding location in the new\n",
    "    data frame.The column of the the transcription factor in the new data frame that corresponds\n",
    "    to the old data frame is incremented by 1. The enhancer column in the new data frame is\n",
    "    set to 1 if that column in the old data frame is 1.\n",
    "    \n",
    "    Args:\n",
    "        new_df(pd.DataFrame): Data frame that is updated\n",
    "        old_df(pd.DataFrame): Data frame that contains the information about transcription factors.\n",
    "    \"\"\"\n",
    "    for row in old_df.itertuples():\n",
    "        # Chromosome is now in index 1; start location in index 2; end location in index 3 of row.\n",
    "        # Match chromosome, start location, and end location from the old and new data frames\n",
    "        # and update the corresponding column of the transcription factor in the new data frame.\n",
    "        new_df.loc[((new_df[\"chr\"] == row[1]) & \n",
    "                (new_df[\"start\"] == row[2]) &\n",
    "                (new_df[\"end\"] == row[3])), [row[9]]] += 1\n",
    "    \n",
    "        # Update the enhancer column as needed.\n",
    "        if row[14] == \"1\":\n",
    "            new_df.loc[((te_new_df[\"chr\"] == row[1]) & \n",
    "                (new_df[\"start\"] == row[2]) &\n",
    "                (new_df[\"end\"] == row[3])), \"enhancer_actual\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, df):\n",
    "    \"\"\"test_model checks how well the model performs and writes output to /results directory\n",
    "    \n",
    "    Args:\n",
    "        model(sklearn.ensemble.RandomForestClassifier): The machine learning model to test\n",
    "        df(pd.DataFrame): The original data; used to compare results with labels.\n",
    "    \"\"\"\n",
    "    # Get index number for the \"y\" vector for machine learning model.\n",
    "    end_index = len(df.columns) - 1\n",
    "    # Set the machine learning input vector as all columns of transcription factors.\n",
    "    x_df = df.copy().iloc[:,3:end_index]\n",
    "    # Set the machine learning prediction vector as the last column, which tells if enhancer is present.\n",
    "    y_actual = df.copy().iloc[:,end_index]\n",
    "    \n",
    "    # Perform 5-fold cross validation on the random forest model.\n",
    "    cvs = cross_val_score(model, x_df, y_actual, cv = 5)\n",
    "    # Print the cross validation scores to a file.\n",
    "    cvs_df = pd.DataFrame(data = cvs, index = [\"cvs 1\", \"cvs 2\", \"cvs 3\", \"cvs 4\", \"cvs 5\"], columns = [\"score\"])\n",
    "    cvs_df.to_csv((DIRECTORY + \"results/\" + DATE + LOC + \"cross_val_scores.csv\"), sep = '\\t', index = False)\n",
    "    \n",
    "    # Create predictions using 5-fold cross validation to view incorrect predictions.\n",
    "    y_pred = cross_val_predict(model, x_df, y_actual, cv = 5)\n",
    "    # Convert the prediction results to a dataframe.\n",
    "    predictions_df = pd.DataFrame(data = y_pred, columns = [\"enhancer_predicted\"])\n",
    "    # Create a dataframe to combine predictions with actual data.\n",
    "    output_df = pd.DataFrame(df.copy()[[\"chr\", \"start\", \"end\", \"enhancer_actual\"]])\n",
    "    # Copy over predictions and print to csv file.\n",
    "    output_df[\"enhancer_predicted\"] = predictions_df\n",
    "    output_df.to_csv((DIRECTORY + \"results/\" + DATE +  LOC + \"predictions.csv\"), sep = '\\t')\n",
    "    \n",
    "    # Create a confusion matrix and write to file.\n",
    "    cm_df = pd.DataFrame(metrics.confusion_matrix(y_actual, y_pred), index = [\"actual_negative\", \"actual_positive\"]\n",
    "                    , columns = [\"predicted_negative\", \"predicted_positive\"])\n",
    "    cm_df.to_csv((DIRECTORY + \"results/\" + DATE + LOC + \"confusion_matrix.csv\"), sep = '\\t')\n",
    "    \n",
    "    # Create a file to store metrics.\n",
    "    metrics_file = open((DIRECTORY + \"results/\" + DATE + LOC + \"metrics.txt\"), \"w+\")\n",
    "    metrics_file.write(metrics.classification_report(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Main\n",
    "\n",
    "# Open the transposable elements data as a dataframe.\n",
    "te_df = pd.read_table((DIRECTORY + \"data/2018_06_12_te_enhancers_ml/\" + DATA_FILE), header = None)\n",
    "# Drop duplicates and reindex\n",
    "te_new_df = remove_dups(old_df = te_df.iloc[:,0:3], col_names = [\"chr\", \"start\", \"end\"])\n",
    "# Get the set of all transcription factors as column labels.\n",
    "col_set = set(te_df.iloc[:,8])\n",
    "# Add in all transcription factors as column labels, as well as an enhancer column\n",
    "col_labels(df = te_new_df, col_list = list(col_set))\n",
    "# Update the new dataframe by going through the original dataframe and updating count of transcription\n",
    "# factor overlap and presence of enhancers as needed.\n",
    "#update_tf(new_df = te_new_df, old_df = te_df)\n",
    "\n",
    "# # Create a random forest classifier model\n",
    "# rfc = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "# # Test the random forest classifer model\n",
    "# test_model(model = rfc, df = te_new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create groups based on chromosome, start location, end location, transcription factor, and if\n",
    "# transcription factor is present. Get the size of each of those groups, and use unstack to \n",
    "# change the transcription factors to column indices to create matrix for machine learning input.\n",
    "# Use reset index to bring all other labels to top level.\n",
    "new_df = te_df.groupby([CHROMOSOME, START, END, TF, ENHANCER], sort = False).size().unstack(TF, fill_value = 0).reset_index()\n",
    "\n",
    "# Reformat enhancer column to have 1 or 0 value.\n",
    "new_df[ENHANCER] = new_df[ENHANCER].apply(lambda x: 1 if x == \"1\" else 0)\n",
    "\n",
    "# Rename the columns\n",
    "new_df.rename(columns = {CHROMOSOME: \"chr\", START: \"start\", END: \"end\", ENHANCER: \"enhancer\"}, inplace = True)\n",
    "\n",
    "# Sum any repeated rows (in case any rows were identical other than enhancer presence)\n",
    "new_df.groupby(new_df.index).sum()\n",
    "\n",
    "# Move row with enhancer to the end.\n",
    "enhancer_df = new_df.copy()[\"enhancer\"]\n",
    "new_df.drop(labels = [\"enhancer\"], axis = 1, inplace = True)\n",
    "new_df.insert(len(new_df.columns), \"enhancer\", enhancer_df)\n",
    "\n",
    "new_df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
