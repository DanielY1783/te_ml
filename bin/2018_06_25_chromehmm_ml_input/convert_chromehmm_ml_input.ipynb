{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes in the formatted intersection of enhancers and transposable elements (with transcription factors) at /dors/capra_lab/users/yand1/te_ml/data/2018_06_22_chromehmm/full_chromehmm.tsv and converts it to a matrix with rows as transposable elements columns as transcription factors (each transcription factor is given one column) and if enhancer overlaps with transposable element. This is stored at /dors/capra_lab/users/yand1/te_ml/data/2018_06_25_chromehmm_ml_input/ to be used as input data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd # For getting data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class constants\n",
    "DATE = \"2018_06_25_chromehmm_ml_input/\" \n",
    "DIRECTORY = \"../../\" # Root directory\n",
    "LOC = \"local/\" # local or accre cluster\n",
    "DATA_FILE = \"test.tsv\" # Name of data file to process\n",
    "X_FILE = \"x_chromehmm.tsv\" # Name of file to save \"x\" input machine learning vector to\n",
    "Y_FILE = \"y_chromehmm.tsv\" # Name of file to save \"y\" prediction machine learning vector to\n",
    "CHROMOSOME = 4 # Column for the chromosome number of transposable element\n",
    "START = 5 # Column for the start location of transposable element\n",
    "END = 6 # Column for the end location of transposable element\n",
    "TF = 3 # Column for the name of the transcription factor intersecting with transposable element\n",
    "ENHANCER = 9 # Column for if enhancer is present. -1 means enhancer is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df (old_df):\n",
    "    \"\"\"transform_tf updates the columns of transcription factors in new_df by cross referencing old_df\n",
    "    \n",
    "    Each row in the old data frame is matched to the corresponding location in the new\n",
    "    data frame.The column of the the transcription factor in the new data frame that corresponds\n",
    "    to the old data frame is incremented by 1. The enhancer column in the new data frame is\n",
    "    set to 1 if that column in the old data frame is 1.\n",
    "    \n",
    "    Args:\n",
    "        old_df(pd.DataFrame): Data frame that contains the information about transcription factors.\n",
    "        \n",
    "    Return:\n",
    "        new_df(pd.DataFrame): New data frame that has columns with the number of times\n",
    "            each transposable element in different locations intersects with each\n",
    "            transcription factor, as well as if an enhancer site is present.\n",
    "    \"\"\"\n",
    "    # Create groups based on chromosome, start location, end location, transcription factor, and if\n",
    "    # transcription factor is present. Get the size of each of those groups, and use unstack to \n",
    "    # change the transcription factors to column indices to create matrix for machine learning input.\n",
    "    # Use reset_index to bring all other labels to top level.\n",
    "    new_df = te_df.groupby([TF, CHROMOSOME, START, END, ENHANCER], sort = False).size()\n",
    "    #.unstack(TF, fill_value = 0).reset_index()\n",
    "\n",
    "#     # Reformat enhancer column to have 1 or 0 value.\n",
    "#     new_df[ENHANCER] = new_df[ENHANCER].apply(lambda x: 0 if x == \"-1\" else 1)\n",
    "\n",
    "#     # Rename the columns\n",
    "#     new_df.rename(columns = {CHROMOSOME: \"chr\", START: \"start\", END: \"end\", ENHANCER: \"enhancer\"}, inplace = True)\n",
    "\n",
    "#     # Sum any repeated rows (in case any rows were identical other than enhancer presence)\n",
    "#     new_df.groupby(new_df.index).sum()\n",
    "\n",
    "#     # Move row with enhancer to the end.\n",
    "#     enhancer_df = new_df.copy()[\"enhancer\"]\n",
    "#     new_df.drop(labels = [\"enhancer\"], axis = 1, inplace = True)\n",
    "#     new_df.insert(len(new_df.columns), \"enhancer_actual\", enhancer_df)\n",
    "    \n",
    "    new_df.head()\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c0bf49722be5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# element, the number of intersections with each transcription factor, and if there is an overlap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# with an enhancer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mte_new_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# # Get index number for the \"y\" vector for machine learning model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5e5a3ae84427>\u001b[0m in \u001b[0;36mtransform_df\u001b[1;34m(old_df)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# change the transcription factors to column indices to create matrix for machine learning input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Use reset_index to bring all other labels to top level.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mte_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHROMOSOME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTART\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mENHANCER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;31m#.unstack(TF, fill_value = 0).reset_index()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   6657\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   6658\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6659\u001b[1;33m                        observed=observed, **kwargs)\n\u001b[0m\u001b[0;32m   6660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6661\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    597\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                     \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m   3289\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3290\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3291\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3292\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3293\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "## Main\n",
    "\n",
    "# Open the transposable elements data as a dataframe.\n",
    "te_df = pd.read_table((DIRECTORY + \"data/2018_06_22_chromehmm/\" + DATA_FILE), header = None)\n",
    "\n",
    "# Create new data frame for machine learning model by setting columns as the different transcription\n",
    "# factors from the original data frame. Each row will now have the location of the transposable \n",
    "# element, the number of intersections with each transcription factor, and if there is an overlap\n",
    "# with an enhancer.\n",
    "te_new_df = transform_df(te_df)\n",
    "\n",
    "# # Get index number for the \"y\" vector for machine learning model.\n",
    "# end_index = len(te_new_df.columns) - 1\n",
    "# # Set the \"x\" machine learning input vector as all columns of transcription factors.\n",
    "# x_df = te_new_df.iloc[:,3:end_index]\n",
    "# # Set the \"y\" machine learning prediction vector as the last column, which tells if enhancer is present.\n",
    "# y_df = te_new_df.iloc[:,end_index]\n",
    "\n",
    "# # Save the \"x\" input vector to a file\n",
    "# x_df.to_csv(DIRECTORY + \"data/\" + DATE + X_FILE, sep = '\\t', index = False)\n",
    "# # Save the \"y\" prediction vector to a file\n",
    "# y_df.to_csv(DIRECTORY + \"data/\" + DATE + Y_FILE, sep = '\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
