{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Daniel Yan\n",
    "\n",
    "Date: 2018-07-16\n",
    "\n",
    "Email: daniel.yan@vanderbilt.edu\n",
    "\n",
    "Description:\n",
    "PCA on data to reduce to \"n\" components for TSNE. \n",
    "\n",
    "Command Line Arguments:\n",
    "First command line argument: Data file to transform. Include directory.\n",
    "Second command line argument: File to store transformed coordinates. Include directory.\n",
    "Third command line argument: File to store the PCA model. Include directory. Must be loaded again\n",
    "    using Scikit-learn joblib.load on same architecture.\n",
    "Fourth command line argument: File to store explained variance to. Include directory.\n",
    "Fifth command line argument: Integer number of components to reduce to.\n",
    "\n",
    "Exception will be thrown if any arguments are missing or invalid.\n",
    "\n",
    "\n",
    "Data file format:\n",
    "The features to be transformed should be 6-mer counts in columns named \"aaaaaa\" to \"tttttt\". Each row should have a label in a column named \"label\"\n",
    "\n",
    "Output file format:\n",
    "The transformed coordinates will be in columns 0 to \"n-1\" of the output file, and the labels will be in column \"n\" of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libaries\n",
    "import pandas as pd # Data manipulation \n",
    "import sys # Command line arguments\n",
    "import pca # Labeling components\n",
    "from sklearn.decomposition import IncrementalPCA # Incremental PCA on large data set\n",
    "from sklearn.externals import joblib # Save PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Get data file to process\n",
    "    data_file = sys.argv[1]\n",
    "    # Get file to store transformed coordinates\n",
    "    cords_file = sys.argv[2]\n",
    "    # Get file to store PCA model to\n",
    "    model_file = sys.argv[3]\n",
    "    # Get file to store explained variances to\n",
    "    variances_file = sys.argv[4]\n",
    "    # Get number of components to reduce to using PCA\n",
    "    n_components = sys.argb[5]\n",
    "    \n",
    "    # Load in data file\n",
    "    print(\"Loading data file...\")\n",
    "    data_file = pd.read_table(data_file)\n",
    "\n",
    "    # Get features used in PCA\n",
    "    features_df = data_file.loc[:,\"aaaaaa\":\"tttttt\"]\n",
    "\n",
    "    # Get labels\n",
    "    labels_df = data_file.loc[:,\"label\"]\n",
    "    \n",
    "    # Create the PCA\n",
    "    print(\"Creating PCA...\")\n",
    "    ipca = IncrementalPCA(n_components = n_components)\n",
    "    features_transformed = ipca.fit_transform(features_df)\n",
    "\n",
    "    # Label the transformed coordinates\n",
    "    transformed_df = pca.label_coordinates(transformed_coordinates = features_transformed, \n",
    "                                           labels = labels_df)\n",
    "    \n",
    "    # Save the transformed coordinates\n",
    "    print(\"Saving new coordinates...\")\n",
    "    transformed_df.to_csv(cords_file, sep = '\\t', index = False)\n",
    "    \n",
    "    # Save the PCA model\n",
    "    print(\"Saving PCA...\")\n",
    "    joblib.dump(ipca, model_file)\n",
    "    \n",
    "    # Save the explained variances\n",
    "    print(\"Saving explained variance...\")\n",
    "    with open(variances_file) as file:\n",
    "        count = 1\n",
    "        sum = 0\n",
    "        # Save the explained variance for each individual component\n",
    "        for i in ipca.explained_variance_ratio_:\n",
    "            file.write(\"Explained Variance Ratio for Component {}: {}%\\n\".format(count, i * 100))\n",
    "            count += 1\n",
    "            sum += i * 100\n",
    "        # Save the combined explained variance from all components\n",
    "        file.write(\"Total explained ratio: {}%\\n\".format(sum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
